# GitHub Actions workflow for testing and code quality
#
# This workflow builds the Debug configuration with coverage enabled,
# runs unit tests (C, Python, and Rust), collects coverage data, and 
# performs static analysis including SonarCloud scanning.
#
# Action Versions (hash-pinned per SPS v2.1):
# - actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 (v4.2.2)
# - actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b (v5.3.0)
# - actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 (v4.4.3)
# - actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 (v4.1.8)
# - dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b (stable)
# - Swatinem/rust-cache@f0deed1e0edfc6a9be95417288c0e1099b1eeec3 (v2.7.7)
# - taiki-e/install-action@1ee706eb04986370fc60419ba172594c51067f29 (v2.62.58)
# - SonarSource/sonarqube-scan-action@fd88b7d7ccbaefd23d8f36f73b59db7a3d246602 (v6.0.0)
# - EnricoMi/publish-unit-test-result-action@170bf24d20d201b842d7a52403b73ed297e6645b (v2.18.0)
#
# Runner Notes:
# - ubuntu-22.04: Standard GitHub-hosted runner (x86_64)
# - ubuntu-22.04-arm: GitHub-hosted ARM64 runner for building aarch64 binaries
# - nxp-imx8mp-latest: NXP i.MX 8M Plus EVK - test-only runner (no toolchain)
#
# Build Strategy:
# - x86_64 and aarch64 builds happen on GitHub-hosted runners
# - imx8mp runner downloads aarch64 artifacts and runs tests only
# - This allows hardware-accelerated testing without requiring a full toolchain
#
# Coverage Strategy:
# - Each platform runs tests independently and generates coverage
# - Coverage artifacts are uploaded from all platforms
# - Dedicated sonarcloud job downloads and merges all coverage reports
#
# Testing Strategy (SPS v2.1):
# - Uses pytest-cov for Python coverage (more reliable than slipcover)
# - Uses cargo-nextest for Rust tests with JUnit XML output
# - Captures test performance metrics with /usr/bin/time -v
# - Publishes test results with EnricoMi/publish-unit-test-result-action
# - Host/Client IPC tests on GitHub runners use POSIX shared memory fallback
# - Host/Client IPC tests on hardware use DMA heap for zero-copy frame sharing
# - On-target vsl-camhost tests verify camera streaming at multiple resolutions
#   (640x480, 1280x720, 1920x1080) with real camera hardware

name: Test

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  # ===========================================================================
  # Build and Test on GitHub-hosted runners (x86_64 and aarch64)
  # ===========================================================================
  build-and-test:
    name: Build & Test (${{ matrix.platform.name }})
    runs-on: ${{ matrix.platform.runner }}
    permissions:
      contents: read
      checks: write
      pull-requests: write
    env:
      BUILD_WRAPPER_OUT_DIR: build/sonar
    strategy:
      matrix:
        platform:
          - name: x86_64
            runner: ubuntu-22.04
          - name: aarch64
            runner: ubuntu-22.04-arm
      fail-fast: false

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2
        with:
          fetch-depth: 0  # Full history for SonarCloud

      - name: Set up Python
        uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b  # v5.3.0
        with:
          python-version: '3.10'

      - name: Create Python virtual environment
        run: |
          python3 -m venv venv
          echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get remove libunwind-* || true
          sudo apt-get install -y --no-install-recommends \
            build-essential cmake pkg-config \
            libgstreamer1.0-dev \
            libgstreamer-plugins-base1.0-dev \
            gstreamer1.0-tools \
            gstreamer1.0-plugins-good \
            gstreamer1.0-plugins-bad \
            python3-dev \
            libxml2-dev libxslt1-dev zlib1g-dev \
            lcov gcovr

      - name: Install Build Wrapper
        uses: SonarSource/sonarqube-scan-action/install-build-wrapper@fd88b7d7ccbaefd23d8f36f73b59db7a3d246602  # v6.0.0

      - name: Detect build wrapper binary
        id: build-wrapper
        run: |
          # Detect architecture and set the correct build wrapper binary
          ARCH=$(uname -m)
          if [ "$ARCH" = "x86_64" ]; then
            echo "binary=build-wrapper-linux-x86-64" >> $GITHUB_OUTPUT
          elif [ "$ARCH" = "aarch64" ]; then
            echo "binary=build-wrapper-linux-aarch64" >> $GITHUB_OUTPUT
          else
            echo "Unsupported architecture: $ARCH"
            exit 1
          fi
          echo "Detected architecture: $ARCH"

      - name: Configure CMake
        run: |
          cmake -S . -B build \
                -DCMAKE_BUILD_TYPE=Debug \
                -DENABLE_COVER=ON \
                -DENABLE_VPU=OFF \
                -DENABLE_G2D=OFF \
                -DCMAKE_EXPORT_COMPILE_COMMANDS=ON

      - name: Build with SonarCloud build wrapper
        run: |
          ${{ steps.build-wrapper.outputs.binary }} --out-dir ${{ env.BUILD_WRAPPER_OUT_DIR }} \
            cmake --build build -j$(nproc)

      - name: Install Python test dependencies
        run: |
          venv/bin/pip install --upgrade pip setuptools wheel
          venv/bin/pip install pytest pytest-cov pytest-timeout
          venv/bin/pip install -r requirements.txt

      - name: Set up Rust toolchain
        uses: dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b  # stable
        with:
          components: llvm-tools-preview, clippy, rustfmt

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@f0deed1e0edfc6a9be95417288c0e1099b1eeec3  # v2.7.7
        with:
          shared-key: rust-${{ matrix.platform.name }}
          cache-on-failure: true

      - name: Install cargo tools
        uses: taiki-e/install-action@1ee706eb04986370fc60419ba172594c51067f29  # v2.62.58
        with:
          tool: cargo-llvm-cov@0.6.16,cargo-nextest

      - name: Check Rust formatting
        run: cargo fmt --all -- --check

      - name: Run Clippy
        run: cargo clippy --workspace --all-targets --all-features -- -D warnings

      - name: Run Python tests with coverage
        run: |
          set -o pipefail
          export LD_LIBRARY_PATH=$(pwd)/build:$LD_LIBRARY_PATH
          export VIDEOSTREAM_LIBRARY=$(pwd)/build/libvideostream.so
          /usr/bin/time -v venv/bin/pytest tests -v \
            --cov=videostream --cov-report=xml:build/coverage_python.xml \
            --junitxml=build/pytest_results.xml \
            2>&1 | tee build/test-metrics-python-${{ matrix.platform.name }}.txt

      - name: Run Rust tests with coverage
        env:
          LD_LIBRARY_PATH: ${{ github.workspace }}/build:$LD_LIBRARY_PATH
        run: |
          set -o pipefail
          /usr/bin/time -v cargo llvm-cov nextest --workspace --all-features \
            --lcov --output-path build/coverage_rust.lcov 2>&1 | tee build/test-metrics-rust-${{ matrix.platform.name }}.txt

      - name: Add skipped Rust tests to JUnit XML
        run: |
          # nextest doesn't include ignored tests in JUnit output
          # Add them as skipped entries so test counts match hardware (46 total)
          python3 << 'PATCH_JUNIT'
          import xml.etree.ElementTree as ET

          junit_file = "target/nextest/default/test-results.xml"
          tree = ET.parse(junit_file)
          root = tree.getroot()

          # Ignored tests that run on hardware but are skipped on CI
          ignored_tests = [
              ("camera::tests::test_camera_start_stop", "videostream"),
              ("camera::tests::test_camera_enum", "videostream"),
              ("camera::tests::test_camera_invalid", "videostream"),
          ]

          # Find the testsuite and add skipped tests
          for testsuite in root.findall('.//testsuite'):
              for test_name, classname in ignored_tests:
                  testcase = ET.SubElement(testsuite, 'testcase')
                  testcase.set('name', test_name)
                  testcase.set('classname', classname)
                  testcase.set('time', '0.000')
                  skipped = ET.SubElement(testcase, 'skipped')
                  skipped.set('message', 'Test requires camera hardware (run with --include-ignored)')

              # Update test count
              current_tests = int(testsuite.get('tests', 0))
              testsuite.set('tests', str(current_tests + len(ignored_tests)))

          # Update root testsuites count
          current_total = int(root.get('tests', 0))
          root.set('tests', str(current_total + len(ignored_tests)))

          tree.write(junit_file, encoding='UTF-8', xml_declaration=True)
          print(f"Added {len(ignored_tests)} skipped tests to {junit_file}")
          PATCH_JUNIT

      - name: Run host/client IPC tests with coverage
        run: |
          set -o pipefail
          export LD_LIBRARY_PATH=$(pwd)/build:$LD_LIBRARY_PATH

          echo "=== VideoStream Host/Client IPC Test ==="
          echo "Testing inter-process communication via UNIX socket"
          echo "Note: Uses POSIX shared memory on GitHub runners (DMA heap not available)"
          echo ""

          SOCKET_PATH="/tmp/videostream_ci_test_$$"
          NUM_FRAMES=30

          # Start host in background
          echo "Starting host..."
          ./build/src/vsl-test-host "$SOCKET_PATH" &
          HOST_PID=$!

          # Give host time to initialize
          sleep 2

          # Check host is running
          if ! kill -0 $HOST_PID 2>/dev/null; then
            echo "ERROR: Host failed to start"
            exit 1
          fi
          echo "âœ“ Host started (PID: $HOST_PID)"

          # Run client
          echo ""
          echo "Starting client to receive $NUM_FRAMES frames..."
          if ./build/src/vsl-test-client "$SOCKET_PATH" "$NUM_FRAMES"; then
            echo ""
            echo "âœ“ Host/Client IPC test PASSED"
            CLIENT_EXIT=0
          else
            echo ""
            echo "âœ— Host/Client IPC test FAILED"
            CLIENT_EXIT=1
          fi

          # Cleanup
          kill $HOST_PID 2>/dev/null || true
          wait $HOST_PID 2>/dev/null || true
          rm -f "$SOCKET_PATH"

          exit $CLIENT_EXIT

      - name: Build instrumented Rust test binaries for hardware testing (aarch64 only)
        if: matrix.platform.name == 'aarch64'
        env:
          LD_LIBRARY_PATH: ${{ github.workspace }}/build:$LD_LIBRARY_PATH
        run: |
          # Set up coverage environment for building instrumented test binaries
          # This sets RUSTFLAGS with -C instrument-coverage and CARGO_LLVM_COV_TARGET_DIR
          source <(cargo llvm-cov show-env --export-prefix)
          
          # Build test binaries with coverage instrumentation (including ignored tests)
          # Binaries are placed in target/llvm-cov-target/debug/deps/
          cargo nextest run --workspace --all-features --no-run --run-ignored=all
          
          # Copy instrumented test binaries to target/tests for artifact upload
          mkdir -p target/tests
          find target/llvm-cov-target/debug/deps/ -maxdepth 1 -type f -executable \
            -name "videostream*" -exec cp {} target/tests/ \;
          
          echo "Instrumented test binaries:"
          ls -la target/tests/

      - name: Generate C/C++ coverage reports (after all tests that call into libvideostream.so)
        run: |
          # Generate SonarQube-compatible XML coverage report using gcovr
          # This captures coverage from Python tests, Rust tests, and any C tests
          # Note: gcovr --sonarqube produces the format expected by sonar.coverageReportPaths
          gcovr -r . --sonarqube -o build/coverage_c_sonar.xml build/
          
          if [ ! -f build/coverage_c_sonar.xml ]; then
            echo "ERROR: Failed to generate C coverage report"
            exit 1
          fi
          
          # Also generate legacy gcov files (for debugging)
          mkdir -p build/gcov
          (cd build && find . -name "*.gcno" -exec gcov -p {} \; 2>/dev/null || true)
          (cd build && mv *.gcov gcov/ 2>/dev/null || true)
          
          echo "=== C coverage report generated ==="
          head -30 build/coverage_c_sonar.xml

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        if: always()
        with:
          name: coverage-${{ matrix.platform.name }}
          path: |
            build/gcov/
            build/coverage_c_sonar.xml
            build/coverage_python.xml
            build/coverage_rust.lcov
          retention-days: 30

      - name: Upload test results and metadata
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        if: always()
        with:
          name: test-results-${{ matrix.platform.name }}
          path: |
            build/pytest_results.xml
            build/coverage_c.xml
            target/nextest/default/test-results.xml
            build/test-metrics-*-${{ matrix.platform.name }}.txt
          retention-days: 30

      - name: Upload build wrapper output
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        if: always()
        with:
          name: build-wrapper-output-${{ matrix.platform.name }}
          path: ${{ env.BUILD_WRAPPER_OUT_DIR }}
          retention-days: 30

      - name: Upload build artifacts for hardware testing (aarch64 only)
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        if: matrix.platform.name == 'aarch64'
        with:
          name: build-aarch64
          path: |
            build/libvideostream.so*
            build/src/vsl-*
            build/CMakeFiles/**/*.gcno
          retention-days: 7

      - name: Upload Rust test binaries for hardware testing (aarch64 only)
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        if: matrix.platform.name == 'aarch64'
        with:
          name: rust-tests-aarch64
          path: |
            target/tests/
          retention-days: 7

      - name: Upload Rust instrumented objects for coverage processing (aarch64 only)
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        if: matrix.platform.name == 'aarch64'
        with:
          name: rust-llvm-cov-aarch64
          path: |
            target/llvm-cov-target/
          retention-days: 7

      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@170bf24d20d201b842d7a52403b73ed297e6645b  # v2.18.0
        if: always()
        with:
          files: |
            build/pytest_results.xml
            target/nextest/default/test-results.xml
          check_name: Test Results (${{ matrix.platform.name }})
          comment_mode: always
          # ignore_runs helps avoid double-counting when tests report multiple runs
          ignore_runs: true

  # ===========================================================================
  # Hardware Testing on NXP i.MX8M Plus (test-only, no build)
  # ===========================================================================
  hardware-test:
    name: Hardware Test (imx8mp)
    needs: build-and-test
    runs-on: nxp-imx8mp-latest
    permissions:
      contents: read
      checks: write
      pull-requests: write

    steps:
      - name: Clean workspace (self-hosted runner)
        run: |
          # Self-hosted runners persist state between runs
          rm -rf build/ venv/ coverage/ target/ rust-tests/ 2>/dev/null || true
          find . -name "*.gcda" -delete 2>/dev/null || true
          find . -name "*.profraw" -delete 2>/dev/null || true

      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2

      - name: Download aarch64 build artifacts
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          name: build-aarch64
          path: build/

      - name: Download Rust test binaries
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          name: rust-tests-aarch64
          path: rust-tests/

      - name: Make downloaded binaries executable
        run: |
          # Artifact upload/download doesn't preserve execute permissions
          chmod +x build/src/vsl-* 2>/dev/null || true
          chmod +x rust-tests/* 2>/dev/null || true
          echo "Made binaries executable:"
          ls -la build/src/vsl-* 2>/dev/null || echo "No vsl binaries found"
          ls -la rust-tests/* 2>/dev/null || echo "No rust test binaries found"

      - name: Create Python virtual environment
        run: |
          python3 -m venv venv
          echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH

      - name: Install Python test dependencies
        run: |
          venv/bin/pip install --upgrade pip setuptools wheel
          venv/bin/pip install pytest pytest-cov pytest-timeout
          venv/bin/pip install -r requirements.txt

      - name: Debug environment info
        run: |
          echo "=== User and groups ==="
          whoami
          id
          groups
          echo ""
          echo "=== DMA heap devices ==="
          ls -la /dev/dma_heap/ || echo "DMA heap directory not found"
          echo ""
          echo "=== Video devices ==="
          ls -la /dev/video* 2>/dev/null || echo "No video devices found"
          v4l2-ctl --list-devices 2>/dev/null || echo "v4l2-ctl not available"
          echo ""
          echo "=== Camera device /dev/video3 details ==="
          v4l2-ctl --device=/dev/video3 --all 2>&1 || echo "Could not query /dev/video3"
          echo ""
          echo "=== Camera formats on /dev/video3 ==="
          v4l2-ctl --device=/dev/video3 --list-formats-ext 2>&1 || echo "Could not list formats"
          echo ""
          echo "=== Downloaded Rust test binaries ==="
          ls -la rust-tests/
          echo ""
          echo "=== Downloaded build artifacts ==="
          ls -la build/

      - name: Run Python tests with coverage (hardware accelerated)
        env:
          # Redirect gcda files to workspace (processed by ubuntu-22.04-arm job)
          GCOV_PREFIX: ${{ github.workspace }}
          GCOV_PREFIX_STRIP: 5
        run: |
          set -o pipefail
          export LD_LIBRARY_PATH=$(pwd)/build:$LD_LIBRARY_PATH
          export VIDEOSTREAM_LIBRARY=$(pwd)/build/libvideostream.so
          /usr/bin/time -v venv/bin/pytest tests -v \
            --cov=videostream --cov-report=xml:build/coverage_python.xml \
            --junitxml=build/pytest_results.xml \
            2>&1 | tee build/test-metrics-python-imx8mp.txt

      - name: Run pre-built Rust tests with hardware access
        env:
          LD_LIBRARY_PATH: ${{ github.workspace }}/build:$LD_LIBRARY_PATH
          # Redirect gcda files to workspace (processed by ubuntu-22.04-arm job)
          GCOV_PREFIX: ${{ github.workspace }}
          GCOV_PREFIX_STRIP: 5
        run: |
          set -o pipefail
          mkdir -p build/rust-test-results
          
          # Set up profraw collection directory
          export LLVM_PROFILE_FILE="${{ github.workspace }}/build/profraw/imx8mp-%p-%m.profraw"
          mkdir -p build/profraw

          # Track overall test status
          TEST_FAILED=0
          
          # Run each test binary and collect results
          echo "Running pre-built Rust test binaries..."
          for test_bin in rust-tests/*; do
            if [ -x "$test_bin" ] && [ -f "$test_bin" ]; then
              test_name=$(basename "$test_bin")
              echo "=== Running $test_name ==="
              # --include-ignored runs tests marked with #[ignore] (camera tests need real hardware)
              # --test-threads=1 for deterministic execution on hardware
              if ! /usr/bin/time -v "$test_bin" --include-ignored --test-threads=1 2>&1 | tee "build/rust-test-results/${test_name}.txt"; then
                echo "FAILED: $test_name"
                TEST_FAILED=1
              fi
            fi
          done
          
          echo ""
          echo "=== Profraw files generated ==="
          ls -la build/profraw/ || echo "No profraw files generated"
          
          # Fail the step if any test failed
          if [ $TEST_FAILED -ne 0 ]; then
            echo ""
            echo "ERROR: One or more Rust tests failed!"
            exit 1
          fi

      - name: Generate JUnit XML from Rust test results
        if: always()
        run: |
          # Parse Rust test output and generate JUnit XML for the publish action
          # This allows hardware Rust tests to appear in the test results summary
          python3 << 'JUNIT_SCRIPT'
          import os
          import re
          import glob
          from datetime import datetime

          results_dir = "build/rust-test-results"
          output_file = "build/rust_hardware_results.xml"
          
          tests = []
          total_passed = 0
          total_failed = 0
          total_time = 0.0
          
          for txt_file in glob.glob(f"{results_dir}/*.txt"):
              test_binary = os.path.basename(txt_file).replace('.txt', '')
              with open(txt_file, 'r') as f:
                  content = f.read()
              
              # Parse test result line: "test result: ok. X passed; Y failed; Z ignored"
              match = re.search(r'test result: (ok|FAILED)\. (\d+) passed; (\d+) failed; (\d+) ignored', content)
              if match:
                  status = match.group(1)
                  passed = int(match.group(2))
                  failed = int(match.group(3))
                  ignored = int(match.group(4))
                  total_passed += passed
                  total_failed += failed
                  
                  # Parse individual test lines: "test name ... ok/FAILED"
                  for test_match in re.finditer(r'test ([\w:]+) \.\.\. (ok|FAILED|ignored)', content):
                      test_name = test_match.group(1)
                      test_status = test_match.group(2)
                      tests.append({
                          'name': test_name,
                          'classname': test_binary,
                          'status': test_status,
                          'time': '0.001'  # Individual times not available
                      })
          
          # Generate JUnit XML
          timestamp = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')
          with open(output_file, 'w') as f:
              f.write('<?xml version="1.0" encoding="UTF-8"?>\n')
              f.write(f'<testsuites name="rust-hardware" tests="{len(tests)}" failures="{total_failed}" errors="0" timestamp="{timestamp}">\n')
              f.write(f'  <testsuite name="rust-hardware" tests="{len(tests)}" failures="{total_failed}" errors="0">\n')
              for test in tests:
                  f.write(f'    <testcase name="{test["name"]}" classname="{test["classname"]}" time="{test["time"]}"')
                  if test['status'] == 'FAILED':
                      f.write('>\n      <failure message="Test failed"/>\n    </testcase>\n')
                  elif test['status'] == 'ignored':
                      f.write('>\n      <skipped/>\n    </testcase>\n')
                  else:
                      f.write('/>\n')
              f.write('  </testsuite>\n')
              f.write('</testsuites>\n')
          
          print(f"Generated {output_file} with {len(tests)} tests ({total_passed} passed, {total_failed} failed)")
          JUNIT_SCRIPT

      - name: Run host/client IPC tests with coverage (hardware, DMA heap)
        env:
          LD_LIBRARY_PATH: ${{ github.workspace }}/build:$LD_LIBRARY_PATH
          GCOV_PREFIX: ${{ github.workspace }}
          GCOV_PREFIX_STRIP: 5
        run: |
          set -o pipefail

          echo "=== VideoStream Host/Client IPC Test (Hardware) ==="
          echo "Testing inter-process communication with DMA heap zero-copy on real hardware"
          echo ""

          SOCKET_PATH="/tmp/videostream_hw_test_$$"
          NUM_FRAMES=30

          # Start host in background
          echo "Starting host..."
          ./build/src/vsl-test-host "$SOCKET_PATH" &
          HOST_PID=$!

          # Give host time to initialize
          sleep 2

          # Check host is running
          if ! kill -0 $HOST_PID 2>/dev/null; then
            echo "ERROR: Host failed to start"
            exit 1
          fi
          echo "âœ“ Host started (PID: $HOST_PID)"

          # Run client
          echo ""
          echo "Starting client to receive $NUM_FRAMES frames..."
          if ./build/src/vsl-test-client "$SOCKET_PATH" "$NUM_FRAMES"; then
            echo ""
            echo "âœ“ Host/Client IPC test PASSED"
            CLIENT_EXIT=0
          else
            echo ""
            echo "âœ— Host/Client IPC test FAILED"
            CLIENT_EXIT=1
          fi

          # Cleanup
          kill $HOST_PID 2>/dev/null || true
          wait $HOST_PID 2>/dev/null || true
          rm -f "$SOCKET_PATH"

          exit $CLIENT_EXIT

      - name: Run vsl-camhost multi-resolution tests (hardware)
        env:
          LD_LIBRARY_PATH: ${{ github.workspace }}/build:$LD_LIBRARY_PATH
          GCOV_PREFIX: ${{ github.workspace }}
          GCOV_PREFIX_STRIP: 5
        run: |
          set -o pipefail

          echo "=== VSL Camera Host Multi-Resolution Tests ==="
          echo "Testing vsl-camhost with various camera resolutions"
          echo ""

          # Detect camera device - use /dev/video3 on imx8mp (ISI capture)
          CAMERA_DEVICE="/dev/video3"
          if [ ! -e "$CAMERA_DEVICE" ]; then
            echo "WARNING: Camera device $CAMERA_DEVICE not found"
            v4l2-ctl --list-devices 2>/dev/null || true
            echo "Skipping camera tests - no camera available"
            exit 0
          fi

          echo "Using camera device: $CAMERA_DEVICE"
          echo ""

          # Test resolutions (common camera resolutions)
          RESOLUTIONS="640x480 1280x720 1920x1080"
          NUM_FRAMES=10  # Receive 10 frames per resolution test
          TESTS_PASSED=0
          TESTS_FAILED=0

          for RES in $RESOLUTIONS; do
            WIDTH=$(echo $RES | cut -d'x' -f1)
            HEIGHT=$(echo $RES | cut -d'x' -f2)
            SOCKET_PATH="/tmp/camhost_test_${WIDTH}x${HEIGHT}_$$"

            echo "==============================================================================="
            echo "Testing resolution: ${WIDTH}x${HEIGHT}"
            echo "==============================================================================="

            # Start camhost with specified resolution
            echo "Starting vsl-camhost..."
            ./build/src/vsl-camhost -d "$CAMERA_DEVICE" -r "${WIDTH}x${HEIGHT}" -p "$SOCKET_PATH" -V &
            CAMHOST_PID=$!

            # Give camhost time to initialize camera and create socket
            sleep 3

            # Check if camhost is still running
            if ! kill -0 $CAMHOST_PID 2>/dev/null; then
              echo "WARNING: vsl-camhost failed to start for resolution ${WIDTH}x${HEIGHT}"
              echo "This resolution may not be supported by the camera"
              wait $CAMHOST_PID 2>/dev/null || true
              TESTS_FAILED=$((TESTS_FAILED + 1))
              continue
            fi

            # Check socket was created
            if [ ! -S "$SOCKET_PATH" ]; then
              echo "WARNING: Socket not created for resolution ${WIDTH}x${HEIGHT}"
              kill $CAMHOST_PID 2>/dev/null || true
              wait $CAMHOST_PID 2>/dev/null || true
              TESTS_FAILED=$((TESTS_FAILED + 1))
              continue
            fi

            echo "âœ“ vsl-camhost started (PID: $CAMHOST_PID)"

            # Run client to receive frames and verify settings
            echo "Running client to receive $NUM_FRAMES frames..."
            if timeout 30 ./build/src/vsl-test-client "$SOCKET_PATH" "$NUM_FRAMES" 2>&1 | tee /tmp/client_output_$$.txt; then
              # Verify the frame dimensions match expected resolution
              if grep -q "Size:.*${WIDTH}x${HEIGHT}" /tmp/client_output_$$.txt; then
                echo "âœ“ Resolution ${WIDTH}x${HEIGHT} test PASSED"
                echo "  Frames received with correct dimensions"
                TESTS_PASSED=$((TESTS_PASSED + 1))
              else
                echo "âœ— Resolution ${WIDTH}x${HEIGHT} test FAILED"
                echo "  Frame dimensions did not match expected ${WIDTH}x${HEIGHT}"
                cat /tmp/client_output_$$.txt
                TESTS_FAILED=$((TESTS_FAILED + 1))
              fi
            else
              echo "âœ— Resolution ${WIDTH}x${HEIGHT} test FAILED"
              echo "  Client failed to receive frames"
              TESTS_FAILED=$((TESTS_FAILED + 1))
            fi

            # Cleanup
            kill $CAMHOST_PID 2>/dev/null || true
            wait $CAMHOST_PID 2>/dev/null || true
            rm -f "$SOCKET_PATH" /tmp/client_output_$$.txt

            echo ""
            sleep 1  # Brief pause between resolution tests
          done

          echo "==============================================================================="
          echo "VSL Camera Host Multi-Resolution Test Summary"
          echo "==============================================================================="
          echo "Tests passed: $TESTS_PASSED"
          echo "Tests failed: $TESTS_FAILED"

          if [ $TESTS_FAILED -gt 0 ]; then
            echo ""
            echo "Some resolution tests failed. This may be due to camera limitations."
            # Don't fail the job if some resolutions aren't supported
            # At least one resolution should work
            if [ $TESTS_PASSED -eq 0 ]; then
              echo "ERROR: No resolution tests passed!"
              exit 1
            fi
          fi

          echo "âœ“ Camera host multi-resolution tests completed"

      - name: Collect gcda files for processing
        if: always()
        run: |
          # Find all gcda files generated during testing
          echo "=== GCDA files generated ==="
          find build/ -name "*.gcda" -type f 2>/dev/null | head -20 || echo "No gcda files found"
          
          # Create directory structure for gcov processing
          mkdir -p build/gcda-imx8mp
          
          # Copy gcda files preserving directory structure
          if find build/ -name "*.gcda" -type f | head -1 | grep -q .; then
            echo "Copying gcda files..."
            find build/ -name "*.gcda" -type f -exec cp --parents {} build/gcda-imx8mp/ \;
            echo "Copied $(find build/gcda-imx8mp -name '*.gcda' | wc -l) gcda files"
          fi

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        if: always()
        with:
          name: coverage-imx8mp
          path: |
            build/coverage_python.xml
            build/profraw/
            build/gcda-imx8mp/
          retention-days: 30

      - name: Upload test results and metadata
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        if: always()
        with:
          name: test-results-imx8mp
          path: |
            build/pytest_results.xml
            build/test-metrics-*-imx8mp.txt
            build/rust-test-results/
          retention-days: 30

      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@170bf24d20d201b842d7a52403b73ed297e6645b  # v2.18.0
        if: always()
        with:
          files: |
            build/pytest_results.xml
            build/rust_hardware_results.xml
          check_name: Test Results (imx8mp)
          comment_mode: always
          # ignore_runs helps avoid double-counting when tests report multiple runs
          ignore_runs: true

  # ===========================================================================
  # Process Hardware Coverage (gcda -> gcov on ubuntu-22.04-arm)
  # ===========================================================================
  process-hardware-coverage:
    name: Process Hardware Coverage
    needs: [build-and-test, hardware-test]
    runs-on: ubuntu-22.04-arm
    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2

      - name: Download aarch64 build artifacts (contains gcno files)
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          name: build-aarch64
          path: build/

      - name: Download Rust test binaries (for reference)
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          name: rust-tests-aarch64
          path: rust-tests/

      - name: Download Rust instrumented objects (for coverage processing)
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          name: rust-llvm-cov-aarch64
          path: target/llvm-cov-target/

      - name: Download imx8mp coverage artifacts (contains gcda and profraw files)
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          name: coverage-imx8mp
          path: coverage-imx8mp/

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b  # stable
        with:
          toolchain: stable
          components: llvm-tools-preview

      - name: Install gcov tools
        run: |
          sudo apt-get update
          sudo apt-get install -y gcovr

      - name: Process Rust profraw files into coverage report
        run: |
          echo "=== Downloaded llvm-cov-target directory ==="
          ls -la target/llvm-cov-target/ || echo "Directory not found"
          
          echo ""
          echo "=== Profraw files from imx8mp ==="
          find coverage-imx8mp/ -name "*.profraw" -type f || echo "No profraw files found"
          
          PROFRAW_COUNT=$(find coverage-imx8mp/ -name "*.profraw" | wc -l)
          echo "Found $PROFRAW_COUNT profraw files"
          
          if [ "$PROFRAW_COUNT" -eq 0 ]; then
            echo "ERROR: No profraw files found from imx8mp hardware tests"
            exit 1
          fi
          
          echo ""
          echo "=== Downloaded instrumented objects from aarch64 build ==="
          ls -la target/llvm-cov-target/ || echo "No llvm-cov-target directory"
          find target/llvm-cov-target/ -type f -name "*.d" | wc -l | xargs echo "Dep files:"
          find target/llvm-cov-target/ -type f -executable | wc -l | xargs echo "Executables:"
          
          # Find LLVM tools from Rust toolchain
          RUSTUP_HOME=${RUSTUP_HOME:-$HOME/.rustup}
          TOOLCHAIN_ROOT=$(rustc --print sysroot)
          LLVM_PROFDATA=$(find "$TOOLCHAIN_ROOT" -name "llvm-profdata" -type f | head -1)
          LLVM_COV=$(find "$TOOLCHAIN_ROOT" -name "llvm-cov" -type f | head -1)
          
          if [ -z "$LLVM_PROFDATA" ] || [ -z "$LLVM_COV" ]; then
            echo "ERROR: Could not find LLVM tools in Rust toolchain"
            echo "LLVM_PROFDATA: $LLVM_PROFDATA"
            echo "LLVM_COV: $LLVM_COV"
            exit 1
          fi
          
          echo ""
          echo "Using LLVM tools:"
          echo "  llvm-profdata: $LLVM_PROFDATA"
          echo "  llvm-cov: $LLVM_COV"
          
          # Merge profraw files into profdata
          echo ""
          echo "=== Merging profraw files ==="
          mkdir -p build
          "$LLVM_PROFDATA" merge -sparse \
            $(find coverage-imx8mp/ -name "*.profraw" -type f) \
            -o build/imx8mp.profdata
          
          if [ ! -f build/imx8mp.profdata ]; then
            echo "ERROR: Failed to merge profraw files"
            exit 1
          fi
          echo "Created build/imx8mp.profdata"
          
          # Find all instrumented binaries (ELF files in deps directory)
          # Note: Execute permissions are lost during artifact upload/download,
          # so we use 'file' command to identify ELF binaries by content
          echo ""
          echo "=== Finding instrumented binaries ==="
          echo "Contents of debug/deps:"
          ls -la target/llvm-cov-target/debug/deps/ 2>/dev/null | head -30
          
          OBJECT_FILES=""
          # Look for test binaries (videostream-* without extension) and library
          for obj in $(find target/llvm-cov-target/debug/deps -maxdepth 1 -type f ! -name "*.d" ! -name "*.rlib" ! -name "*.rmeta" 2>/dev/null); do
            if file "$obj" | grep -q "ELF"; then
              if [ -z "$OBJECT_FILES" ]; then
                OBJECT_FILES="$obj"
              else
                OBJECT_FILES="$OBJECT_FILES --object=$obj"
              fi
            fi
          done
          
          if [ -z "$OBJECT_FILES" ]; then
            echo "ERROR: No ELF binaries found in target/llvm-cov-target/debug/deps/"
            echo "All files in debug/deps:"
            find target/llvm-cov-target/debug/deps -type f 2>/dev/null | head -30
            exit 1
          fi
          
          echo "Found binaries:"
          echo "$OBJECT_FILES" | tr ' ' '\n' | grep -v "^$" | head -20
          
          # The profraw files were generated on imx8mp where workspace was at /home/runner/work/videostream/videostream
          # Here on ubuntu-22.04-arm, it's at /home/runner/work/videostream/videostream too (same path!)
          # But the instrumented binaries were built on a different aarch64 runner, also at the same path
          # So path-equivalence may not be needed, but let's add it for safety
          AARCH64_WORKSPACE="/home/runner/work/videostream/videostream"
          CURRENT_WORKSPACE="${{ github.workspace }}"
          
          echo ""
          echo "=== Generating LCOV coverage report ==="
          echo "Path mapping: $AARCH64_WORKSPACE -> $CURRENT_WORKSPACE"
          
          # Use llvm-cov export directly with path remapping
          "$LLVM_COV" export \
            --format=lcov \
            --instr-profile=build/imx8mp.profdata \
            --ignore-filename-regex='/.cargo/registry|/rustc/' \
            --path-equivalence="$AARCH64_WORKSPACE","$CURRENT_WORKSPACE" \
            $OBJECT_FILES \
            > build/coverage_rust_imx8mp.lcov
          
          if [ ! -s build/coverage_rust_imx8mp.lcov ]; then
            echo "ERROR: Failed to generate Rust coverage report (empty file)"
            exit 1
          fi
          
          echo "Generated build/coverage_rust_imx8mp.lcov"
          head -20 build/coverage_rust_imx8mp.lcov
          wc -l build/coverage_rust_imx8mp.lcov

      - name: Process gcda files into SonarQube coverage format
        run: |
          echo "=== Build artifacts (gcno files) ==="
          find build/ -name "*.gcno" -type f | head -20 || echo "No gcno files found"
          
          echo ""
          echo "=== Coverage artifacts from imx8mp ==="
          find coverage-imx8mp/ -name "*.gcda" -type f | head -20 || echo "No gcda files found"
          
          # Move gcda files to match gcno file locations
          if find coverage-imx8mp/ -name "*.gcda" -type f | head -1 | grep -q .; then
            echo ""
            echo "=== Relocating gcda files to match gcno locations ==="
            # The gcda files need to be in the same directory as their corresponding gcno files
            find coverage-imx8mp/ -name "*.gcda" -type f | while read gcda; do
              # Extract the relative path from the gcda file
              gcda_name=$(basename "$gcda")
              # Find matching gcno file
              gcno_path=$(find build/ -name "${gcda_name%.gcda}.gcno" -type f | head -1)
              if [ -n "$gcno_path" ]; then
                gcno_dir=$(dirname "$gcno_path")
                echo "Copying $gcda_name to $gcno_dir/"
                cp "$gcda" "$gcno_dir/"
              else
                echo "WARNING: No matching gcno for $gcda_name"
              fi
            done
          fi
          
          # Generate SonarQube-compatible XML coverage report
          echo ""
          echo "=== Generating SonarQube coverage report ==="
          gcovr -r . --sonarqube -o build/coverage_c_imx8mp_sonar.xml build/
          
          if [ ! -f build/coverage_c_imx8mp_sonar.xml ]; then
            echo "ERROR: Failed to generate C coverage report for imx8mp"
            exit 1
          fi
          echo "Generated build/coverage_c_imx8mp_sonar.xml"
          head -30 build/coverage_c_imx8mp_sonar.xml

      - name: Upload processed coverage
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882  # v4.4.3
        with:
          name: coverage-imx8mp-processed
          path: |
            build/coverage_c_imx8mp_sonar.xml
            build/coverage_rust_imx8mp.lcov
            coverage-imx8mp/build/coverage_python.xml
          retention-days: 30

  # ===========================================================================
  # SonarCloud Analysis (aggregates coverage from all platforms)
  # ===========================================================================
  sonarcloud:
    name: SonarCloud Analysis
    needs: [build-and-test, hardware-test, process-hardware-coverage]
    runs-on: ubuntu-22.04
    if: github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository
    permissions:
      contents: read
      pull-requests: read

    steps:
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2
        with:
          fetch-depth: 0  # Full history for SonarCloud blame data

      - name: Install C/C++ analysis dependencies
        run: |
          # SonarCloud needs system headers referenced in compile_commands.json
          # to properly analyze C/C++ code and resolve includes
          sudo apt-get update
          sudo apt-get remove libunwind-* || true
          sudo apt-get install -y --no-install-recommends \
            libgstreamer1.0-dev \
            libgstreamer-plugins-base1.0-dev \
            libglib2.0-dev

      - name: Download all coverage artifacts
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          pattern: coverage-*
          path: coverage/

      - name: Download all build wrapper outputs
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        with:
          pattern: build-wrapper-output-*
          path: build-wrapper/

      - name: Organize coverage files for SonarCloud
        run: |
          # List all downloaded artifacts for debugging
          echo "=== Downloaded coverage artifacts ==="
          find coverage/ -type f
          echo ""
          echo "=== Downloaded build wrapper outputs ==="
          find build-wrapper/ -type f | head -20
          
          # Create consolidated directory structure
          mkdir -p build/sonar
          
          # Use x86_64 build wrapper output (all platforms produce similar data)
          # Build wrapper generates compile_commands.json which SonarCloud uses
          # for C/C++ analysis with sonar.cfamily.compile-commands parameter
          if [ -d "build-wrapper/build-wrapper-output-x86_64" ]; then
            cp -r build-wrapper/build-wrapper-output-x86_64/* build/sonar/
          fi
          
          # Verify compile_commands.json exists (generated by build-wrapper)
          if [ -f "build/sonar/compile_commands.json" ]; then
            echo "Found compile_commands.json from build wrapper"
            echo "Number of compilation units: $(grep -c '"file"' build/sonar/compile_commands.json)"
          else
            echo "ERROR: compile_commands.json not found in build wrapper output"
            echo "Contents of build/sonar/:"
            ls -la build/sonar/ || echo "Directory does not exist"
            exit 1
          fi
          
          # Fix Python coverage XML paths for Sonar
          # The fix_coverage_paths.py script normalizes paths by:
          # 1. Converting absolute <source> paths to relative package path
          # 2. Adding package prefix to all filename attributes
          echo ""
          echo "=== Fixing Python coverage report paths for SonarCloud ==="
          for python_xml in $(find coverage/ -name "coverage_python.xml" -type f); do
            echo "Fixing: $python_xml"
            python3 scripts/fix_coverage_paths.py "$python_xml" videostream
          done
          
          # Collect all coverage reports
          # Python coverage (Cobertura XML format)
          PYTHON_REPORTS=$(find coverage/ -name "coverage_python.xml" | tr '\n' ',' | sed 's/,$//')
          
          # Rust coverage (LCOV format)
          RUST_REPORTS=$(find coverage/ -name "coverage_rust*.lcov" | tr '\n' ',' | sed 's/,$//')
          
          # C/C++ coverage (SonarQube XML format from gcovr --sonarqube)
          C_REPORTS=$(find coverage/ -name "coverage_c*_sonar.xml" | tr '\n' ',' | sed 's/,$//')
          
          echo ""
          echo "=== Coverage report paths ==="
          echo "Python coverage reports: $PYTHON_REPORTS"
          echo "Rust coverage reports: $RUST_REPORTS"
          echo "C/C++ coverage reports: $C_REPORTS"
          
          # Show sample of coverage report to verify source path normalization
          SAMPLE_REPORT=$(find coverage/ -name "*.xml" | head -1)
          if [ -n "$SAMPLE_REPORT" ] && [ -f "$SAMPLE_REPORT" ]; then
            echo ""
            echo "=== Sample coverage report (first 15 lines) ==="
            head -15 "$SAMPLE_REPORT"
          fi
          
          # Export for next step
          echo "PYTHON_COVERAGE_PATHS=$PYTHON_REPORTS" >> $GITHUB_ENV
          echo "RUST_COVERAGE_PATHS=$RUST_REPORTS" >> $GITHUB_ENV
          echo "C_COVERAGE_PATHS=$C_REPORTS" >> $GITHUB_ENV

      - name: Run SonarCloud scan
        uses: SonarSource/sonarqube-scan-action@fd88b7d7ccbaefd23d8f36f73b59db7a3d246602  # v6.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          args: >
            -Dsonar.python.coverage.reportPaths=${{ env.PYTHON_COVERAGE_PATHS }}
            -Dsonar.rust.lcov.reportPaths=${{ env.RUST_COVERAGE_PATHS }}
            -Dsonar.coverageReportPaths=${{ env.C_COVERAGE_PATHS }}
            -Dsonar.cfamily.compile-commands=build/sonar/compile_commands.json
            -Dsonar.cfamily.analysisCache.mode=fs
            -Dsonar.cfamily.analysisCache.path=${{ runner.temp }}/cfamily-cache

      - name: Generate test and coverage summary
        if: always()
        run: |
          echo "# ðŸ“Š VideoStream Test & Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test platforms summary
          echo "## ðŸ§ª Test Platforms" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | Architecture | Environment | Tests |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|--------------|-------------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Ubuntu 22.04 | x86_64 | GitHub Runner | C, Rust, Python, IPC (shared memory) |" >> $GITHUB_STEP_SUMMARY
          echo "| Ubuntu 22.04 | aarch64 | GitHub ARM Runner | C, Rust, Python, IPC (shared memory) |" >> $GITHUB_STEP_SUMMARY
          echo "| NXP i.MX8M Plus | aarch64 | Real Hardware | C, Rust, Python, IPC (DMA heap), Camera Multi-Resolution |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Use standalone coverage summary script (also used by `make test`)
          # Use --github-actions flag to read paths from environment variables
          python3 scripts/coverage_summary.py --github-actions >> $GITHUB_STEP_SUMMARY
          
          # =====================================================================
          # SonarCloud Links
          # =====================================================================
          echo "## ðŸ”— SonarCloud Dashboard" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- [ðŸ“Š Overall Code](https://sonarcloud.io/summary/overall?id=EdgeFirstAI_videostream&branch=${{ github.ref_name }})" >> $GITHUB_STEP_SUMMARY
          echo "- [ðŸ“ Coverage by File](https://sonarcloud.io/component_measures?id=EdgeFirstAI_videostream&metric=coverage&view=list&branch=${{ github.ref_name }})" >> $GITHUB_STEP_SUMMARY
